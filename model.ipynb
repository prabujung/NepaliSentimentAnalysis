{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15001, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/dataset.csv')\n",
    "df = df.loc[:15000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col = df.iloc[1:, 0]\n",
    "second_col = df.iloc[1:, 1]\n",
    "second_col = second_col.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_file = open(\"./data/stopwords.txt\",\"r\",encoding=\"utf-8\")\n",
    "stop_words = stop_words_file.read()\n",
    "stop_words = stop_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning method\n",
    "def data_cleaning(string):\n",
    "    text = re.sub('\\,|\\@|\\-|\\\"|\\'| \\)|\\(|\\)| \\{| \\}| \\[| \\]|!|‘|’|“|”| \\:-|\\?|।|/|\\—|\\०|\\१|\\२|\\३|\\४|\\५|\\६|\\७|\\८|\\९|[0-9]', '', string)\n",
    "    return text\n",
    "\n",
    "def stop_word_remove(array_element):\n",
    "    array_element_set = set(array_element)\n",
    "    final_list = list(array_element_set.difference(stop_words))\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize():\n",
    "    data_with_split = []\n",
    "    for data in first_col:\n",
    "        return_string = data_cleaning(data)\n",
    "        each_docs = return_string.split(\" \")\n",
    "        string_after_remove_word=stop_word_remove(each_docs)\n",
    "        \n",
    "        data_with_split.append(each_docs)\n",
    "    return data_with_split  # it returns arr of each docs with spleted words\n",
    "\n",
    "\n",
    "\n",
    "corpus = tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFVectorizer:\n",
    "    def __init__(self):\n",
    "        self.idf = None\n",
    "        self.vocabulary = set()\n",
    "        \n",
    "        # Build vocabulary\n",
    "        for document in corpus:\n",
    "            self.vocabulary.update(document)\n",
    "        self.vocabulary = list(self.vocabulary)\n",
    "\n",
    "    def get_tif_idf_info(self,words,sentence_feature):\n",
    "        tf_idf_info = {}\n",
    "        for word in words:\n",
    "            index = self.vocabulary.index(word)\n",
    "            tf_idf_info[word]=sentence_feature[0][index]\n",
    "        return tf_idf_info\n",
    "    \n",
    "    def fit_transform(self, corpus):\n",
    "        # Calculate IDF\n",
    "        idf = {}\n",
    "        N = len(corpus)\n",
    "        for term in self.vocabulary:\n",
    "            df = sum(1 for document in corpus if term in document)\n",
    "            idf[term] = math.log(N / (1 + df))\n",
    "\n",
    "        # Transform documents to TF-IDF representation\n",
    "        tfidf_matrix = np.zeros((len(corpus), len(self.vocabulary)))\n",
    "        for i, document in enumerate(corpus):\n",
    "            tf = Counter(document)\n",
    "            total_terms = len(document)\n",
    "            for j, term in enumerate(self.vocabulary):\n",
    "                if total_terms != 0:\n",
    "                    tfidf_matrix[i, j] = (tf.get(term, 0) / total_terms) * idf[term]\n",
    "                else:\n",
    "                    tfidf_matrix[i, j] = 0  # Set TF-IDF to 0 if total_terms is 0\n",
    "\n",
    "        self.idf = idf\n",
    "        return tfidf_matrix\n",
    "\n",
    "    def transform(self, corpus):\n",
    "        tfidf_matrix = np.zeros((len(corpus), len(self.vocabulary)))\n",
    "        for i, document in enumerate(corpus):\n",
    "            tf = Counter(document)\n",
    "            total_terms = len(document)\n",
    "            for j, term in enumerate(self.vocabulary):\n",
    "                if total_terms != 0:\n",
    "                    tfidf_matrix[i, j] = (tf.get(term, 0) / total_terms) * self.idf.get(term, 0)\n",
    "                else:\n",
    "                    tfidf_matrix[i, j] = 0  # Set TF-IDF to 0 if total_terms is 0\n",
    "        return tfidf_matrix\n",
    "\n",
    "# Create TFIDFVectorizer instance\n",
    "tfidf_vectorizer = TFIDFVectorizer()\n",
    "\n",
    "# Fit and transform corpus\n",
    "features = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "vectorizer_data = open(\"./webapp/model/vectorizer.pkl\", \"wb\")\n",
    "pickle.dump(tfidf_vectorizer, vectorizer_data)\n",
    "vectorizer_data.close()\n",
    "\n",
    "with open('./webapp/model/vectorizer.pkl', 'rb') as tfidf:\n",
    "    vectorizer = pickle.load(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=features\n",
    "y=second_col\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.2,random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()  \n",
    "TrainData = naive_bayes.fit(train_x, train_y)\n",
    "\n",
    "classifier_data = open(\"./webapp/model/classifier.pkl\", \"wb\")\n",
    "pickle.dump(naive_bayes, classifier_data)\n",
    "classifier_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./webapp/model/classifier.pkl', 'rb') as pickle_saved_data:\n",
    "    unpickled_data = pickle.load(pickle_saved_data)\n",
    "\n",
    "\n",
    "\n",
    "prediction = unpickled_data.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'precision_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall, accuracy, f1_score\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m precision, recall, accuracy, f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_performance_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m metrices \u001b[38;5;241m=\u001b[39m [precision, recall, accuracy, f1_score]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrices)\n",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m, in \u001b[0;36mcalculate_performance_metrics\u001b[0;34m(true_labels, predicted_labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_performance_metrics\u001b[39m(true_labels, predicted_labels):\n\u001b[0;32m----> 2\u001b[0m     precision \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_score\u001b[49m(true_labels, predicted_labels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     recall \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mrecall_score(true_labels, predicted_labels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(true_labels, predicted_labels)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'precision_score'"
     ]
    }
   ],
   "source": [
    "def calculate_performance_metrics(true_labels, predicted_labels):\n",
    "    precision = metrics.precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = metrics.recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    accuracy = metrics.accuracy_score(true_labels, predicted_labels)\n",
    "    f1_score = metrics.f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    return precision, recall, accuracy, f1_score\n",
    "\n",
    "# Example usage:\n",
    "precision, recall, accuracy, f1_score = calculate_performance_metrics(test_y, prediction)\n",
    "\n",
    "metrices = [precision, recall, accuracy, f1_score]\n",
    "print(metrices)\n",
    "with open(\"./webapp/model/metrices.pkl\", \"wb\") as metrices_file:\n",
    "    pickle.dump(metrices, metrices_file)\n",
    "\n",
    "with open('./webapp/model/metrices.pkl', 'rb') as metrics_file:\n",
    "    metrics = pickle.load(metrics_file)\n",
    "\n",
    "print(\"Precision:\",metrics[0])   \n",
    "print(\"Recall:\",metrics[1])  \n",
    "print(\"F1 Score:\",metrics[2])  \n",
    "print(\"Accuracy:\",metrics[3])   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: आज म धेरै खुसी छु।\n",
      "Predicted Sentiment Label: 1\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    # Preprocess the input sentence\n",
    "    cleaned_sentence = data_cleaning(sentence)\n",
    "    tokenized_sentence = cleaned_sentence.split()\n",
    "    stop_word_removed_sentence = stop_word_remove(tokenized_sentence)\n",
    "    \n",
    "    # Transform the preprocessed sentence using TF-IDF vectorizer\n",
    "    sentence_features = vectorizer.transform([stop_word_removed_sentence])\n",
    "\n",
    "    # Use the trained classifier to predict the sentiment label\n",
    "    predicted_label = unpickled_data.predict(sentence_features)\n",
    "\n",
    "    return predicted_label[0]  # Return the predicted sentiment label\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"आज म धेरै खुसी छु।\"\n",
    "predicted_sentiment = predict_sentiment(sentence)\n",
    "print(\"Input sentence:\", sentence)\n",
    "print(\"Predicted Sentiment Label:\", predicted_sentiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
